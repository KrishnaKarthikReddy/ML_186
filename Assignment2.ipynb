{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKWjGtdGvPT3j/KbOqPuIX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrishnaKarthikReddy/ML_186/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting tuning experiment (scikit-learn)\n",
        "# Dataset: sklearn breast cancer\n",
        "# Requires: scikit-learn, pandas, numpy\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# 1. Load data\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# 2. Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Baseline model (default hyperparameters)\n",
        "baseline = GradientBoostingClassifier(random_state=42)\n",
        "start = time.time()\n",
        "cv_scores = cross_val_score(baseline, X_train, y_train, cv=3, scoring='accuracy', n_jobs=1)\n",
        "baseline_time = time.time() - start\n",
        "baseline_cv_mean = cv_scores.mean()\n",
        "\n",
        "baseline.fit(X_train, y_train)\n",
        "y_pred_baseline = baseline.predict(X_test)\n",
        "baseline_test_acc = accuracy_score(y_test, y_pred_baseline)\n",
        "\n",
        "# 4. Hyperparameter tuning with RandomizedSearchCV (light)\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [1, 2, 3, 4],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'max_features': [None, 'sqrt', 'log2', 0.5]\n",
        "}\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "rand = RandomizedSearchCV(gb, param_distributions=param_dist, n_iter=20,\n",
        "                          scoring='accuracy', cv=3, random_state=42, n_jobs=1, verbose=0)\n",
        "\n",
        "start = time.time()\n",
        "rand.fit(X_train, y_train)\n",
        "tuned_time = time.time() - start\n",
        "\n",
        "best_params = rand.best_params_\n",
        "best_score_cv = rand.best_score_\n",
        "\n",
        "best_model = rand.best_estimator_\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "tuned_test_acc = accuracy_score(y_test, y_pred_tuned)\n",
        "tuned_classif_report = classification_report(y_test, y_pred_tuned, target_names=data.target_names, digits=4)\n",
        "tuned_conf_mat = confusion_matrix(y_test, y_pred_tuned)\n",
        "\n",
        "# 5. Results\n",
        "results_summary = {\n",
        "    'baseline_cv_mean': round(baseline_cv_mean,4),\n",
        "    'baseline_test_acc': round(baseline_test_acc,4),\n",
        "    'baseline_fit_time_sec': round(baseline_time,3),\n",
        "    'tuned_cv_mean': round(best_score_cv,4),\n",
        "    'tuned_test_acc': round(tuned_test_acc,4),\n",
        "    'tuned_fit_time_sec': round(tuned_time,3),\n",
        "    'best_params': best_params\n",
        "}\n",
        "\n",
        "print(\"=== Results summary ===\")\n",
        "for k,v in results_summary.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "print(\"\\n=== Top CV results (first few) ===\")\n",
        "cv_results_df = pd.DataFrame(rand.cv_results_).sort_values('rank_test_score').head(6)[['rank_test_score','mean_test_score','std_test_score','params']]\n",
        "print(cv_results_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n=== Tuned model classification report (on test set) ===\")\n",
        "print(tuned_classif_report)\n",
        "print(\"Confusion matrix:\\n\", tuned_conf_mat)\n",
        "\n",
        "# save summary to a file\n",
        "with open('gbm_experiment_results.txt', 'w') as f:\n",
        "    for k,v in results_summary.items():\n",
        "        f.write(f\"{k}: {v}\\n\")\n",
        "    f.write(\"\\nClassification report:\\n\")\n",
        "    f.write(tuned_classif_report + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPmMg-tzJKhw",
        "outputId": "f4f5e91a-e520-4108-e6c2-028fbabe09cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Results summary ===\n",
            "baseline_cv_mean: 0.9561\n",
            "baseline_test_acc: 0.9561\n",
            "baseline_fit_time_sec: 1.594\n",
            "tuned_cv_mean: 0.9758\n",
            "tuned_test_acc: 0.9474\n",
            "tuned_fit_time_sec: 12.224\n",
            "best_params: {'subsample': 0.8, 'n_estimators': 100, 'max_features': 'log2', 'max_depth': 1, 'learning_rate': 0.2}\n",
            "\n",
            "=== Top CV results (first few) ===\n",
            " rank_test_score  mean_test_score  std_test_score                                                                                                 params\n",
            "               1         0.975848        0.011154  {'subsample': 0.8, 'n_estimators': 100, 'max_features': 'log2', 'max_depth': 1, 'learning_rate': 0.2}\n",
            "               2         0.973655        0.010708  {'subsample': 0.6, 'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.1}\n",
            "               3         0.971462        0.013485     {'subsample': 0.8, 'n_estimators': 200, 'max_features': 0.5, 'max_depth': 2, 'learning_rate': 0.2}\n",
            "               4         0.971448        0.006141     {'subsample': 0.8, 'n_estimators': 100, 'max_features': 0.5, 'max_depth': 4, 'learning_rate': 0.2}\n",
            "               5         0.971433        0.008190 {'subsample': 0.6, 'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': 1, 'learning_rate': 0.05}\n",
            "               6         0.967062        0.009242  {'subsample': 0.6, 'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.2}\n",
            "\n",
            "=== Tuned model classification report (on test set) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant     0.9500    0.9048    0.9268        42\n",
            "      benign     0.9459    0.9722    0.9589        72\n",
            "\n",
            "    accuracy                         0.9474       114\n",
            "   macro avg     0.9480    0.9385    0.9429       114\n",
            "weighted avg     0.9474    0.9474    0.9471       114\n",
            "\n",
            "Confusion matrix:\n",
            " [[38  4]\n",
            " [ 2 70]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EkaxRro3J8W4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}